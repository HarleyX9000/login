{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "\n",
        "\n",
        "# Cargar datos\n",
        "data = pd.read_csv('/content/fake_or_real_news.csv')\n",
        "\n",
        "# Análisis exploratorio de variables\n",
        "print(data.head())\n",
        "print(data['label'].value_counts())\n",
        "\n",
        "# Preprocesamiento de datos de texto\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "data['titulo_procesado'] = data['title'].apply(lambda x: simple_preprocess(x))\n",
        "data['texto_procesado'] = data['text'].apply(lambda x: simple_preprocess(x))\n",
        "\n",
        "# Entrenamiento de modelo Word2Vec\n",
        "model_w2v = Word2Vec(sentences=data['titulo_procesado'] + data['texto_procesado'],\n",
        "                     vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Vectorización de texto\n",
        "def vectorizar_texto(titulo, texto, model):\n",
        "    vectors_titulo = []\n",
        "    vectors_texto = []\n",
        "\n",
        "    for word in titulo:\n",
        "        if word in model.wv:\n",
        "            vectors_titulo.append(model.wv[word])\n",
        "\n",
        "    for word in texto:\n",
        "        if word in model.wv:\n",
        "            vectors_texto.append(model.wv[word])\n",
        "\n",
        "    if vectors_titulo and vectors_texto:\n",
        "        vector_titulo = np.mean(vectors_titulo, axis=0)\n",
        "        vector_texto = np.mean(vectors_texto, axis=0)\n",
        "        return np.concatenate([vector_titulo, vector_texto])\n",
        "    else:\n",
        "        return np.zeros(model.vector_size * 2)\n",
        "\n",
        "data['vector_texto'] = data.apply(lambda row: vectorizar_texto(row['titulo_procesado'], row['texto_procesado'], model_w2v), axis=1)\n",
        "\n",
        "# Creación de datos para la red neuronal\n",
        "X = np.vstack(data['vector_texto'].to_numpy())\n",
        "y = (data['label'] == 'FAKE').astype(int)\n",
        "\n",
        "# Definición del modelo de red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=model_w2v.vector_size * 2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Función dummy para test_function\n",
        "@tf.autograph.experimental.do_not_convert\n",
        "def dummy_test_function(self, step_inputs, step_state):\n",
        "    pass\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluación del modelo\n",
        "loss, accuracy = model.evaluate(X, y)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxYfq4zvk8gC",
        "outputId": "76076c2b-867f-4736-b7b3-d68b6a5463df"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                              title  \\\n",
            "0        8476                       You Can Smell Hillary’s Fear   \n",
            "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
            "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
            "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
            "4         875   The Battle of New York: Why This Primary Matters   \n",
            "\n",
            "                                                text label  \n",
            "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
            "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
            "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
            "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
            "4  It's primary day in New York and front-runners...  REAL  \n",
            "REAL    3171\n",
            "FAKE    3164\n",
            "Name: label, dtype: int64\n",
            "Epoch 1/10\n",
            "152/159 [===========================>..] - ETA: 0s - loss: 0.4330 - accuracy: 0.8051"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7d026963bac0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7d026963bac0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.4285 - accuracy: 0.8076 - val_loss: 0.3649 - val_accuracy: 0.8303\n",
            "Epoch 2/10\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.3207 - accuracy: 0.8690 - val_loss: 0.3177 - val_accuracy: 0.8658\n",
            "Epoch 3/10\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2885 - accuracy: 0.8832 - val_loss: 0.2945 - val_accuracy: 0.8769\n",
            "Epoch 4/10\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2747 - accuracy: 0.8899 - val_loss: 0.2821 - val_accuracy: 0.8769\n",
            "Epoch 5/10\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 0.2542 - accuracy: 0.9000 - val_loss: 0.2706 - val_accuracy: 0.8816\n",
            "Epoch 6/10\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.2391 - accuracy: 0.9069 - val_loss: 0.2674 - val_accuracy: 0.8863\n",
            "Epoch 7/10\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.2298 - accuracy: 0.9108 - val_loss: 0.2727 - val_accuracy: 0.8863\n",
            "Epoch 8/10\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.2168 - accuracy: 0.9175 - val_loss: 0.2659 - val_accuracy: 0.8934\n",
            "Epoch 9/10\n",
            "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9223 - val_loss: 0.2670 - val_accuracy: 0.8911\n",
            "Epoch 10/10\n",
            "159/159 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9258 - val_loss: 0.2624 - val_accuracy: 0.8958\n",
            "198/198 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9305\n",
            "Loss: 0.19009771943092346, Accuracy: 0.9305446147918701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías adicionales\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Función para obtener texto de una URL\n",
        "def obtener_texto_desde_url(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Verificar si la solicitud fue exitosa\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        # Ajusta la selección del contenido según la estructura de la página web\n",
        "        contenido = soup.get_text()\n",
        "        return contenido\n",
        "    except Exception as e:\n",
        "        print(f'Error al obtener contenido de la URL: {url}')\n",
        "        print(e)\n",
        "        return None\n",
        "\n",
        "# URL de las dos noticias nuevas\n",
        "url_noticia1 = 'https://www.breitbart.com/politics/2016/09/10/exposed-fbi-director-james-comeys-clinton-foundation-connection/'\n",
        "url_noticia2 = 'https://english.elpais.com/sports/2023-07-24/saudi-arabian-soccer-team-al-hilal-makes-record-332-million-bid-for-france-striker-kylian-mbappe.html'\n",
        "\n",
        "# Obtener texto de las noticias desde las URLs\n",
        "texto_noticia1 = obtener_texto_desde_url(url_noticia1)\n",
        "texto_noticia2 = obtener_texto_desde_url(url_noticia2)\n",
        "\n",
        "# Verificar si se obtuvo un texto válido antes de procesar\n",
        "if texto_noticia1 is not None and texto_noticia2 is not None:\n",
        "    # Preprocesamiento de datos de texto\n",
        "    titulo_noticia1_procesado = simple_preprocess(\"Título de la Noticia 1\")\n",
        "    texto_noticia1_procesado = simple_preprocess(texto_noticia1)\n",
        "\n",
        "    titulo_noticia2_procesado = simple_preprocess(\"Título de la Noticia 2\")\n",
        "    texto_noticia2_procesado = simple_preprocess(texto_noticia2)\n",
        "\n",
        "    # Vectorización de texto\n",
        "    vector_noticia1 = vectorizar_texto(titulo_noticia1_procesado, texto_noticia1_procesado, model_w2v)\n",
        "    vector_noticia2 = vectorizar_texto(titulo_noticia2_procesado, texto_noticia2_procesado, model_w2v)\n",
        "\n",
        "    # Crear datos para la predicción\n",
        "    X_prediccion = np.vstack([vector_noticia1, vector_noticia2])\n",
        "\n",
        "    # Realizar la predicción\n",
        "    predicciones = model.predict(X_prediccion)\n",
        "\n",
        "    # Imprimir resultados\n",
        "    for i, prediccion in enumerate(predicciones):\n",
        "        etiqueta_predicha = 'FAKE' if prediccion < 0.5 else 'REAL'\n",
        "        print(f'Noticia {i + 1}: Etiqueta Predicha: {etiqueta_predicha} (Confianza: {prediccion[0]:.4f})')\n",
        "else:\n",
        "    print('No se pudo obtener texto válido de al menos una de las noticias.')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEQOpNZZtUAL",
        "outputId": "557e5da7-2584-423d-ef10-28a680213eec"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7d024d36de10> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7d024d36de10> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "Noticia 1: Etiqueta Predicha: REAL (Confianza: 0.8394)\n",
            "Noticia 2: Etiqueta Predicha: REAL (Confianza: 0.9185)\n"
          ]
        }
      ]
    }
  ]
}